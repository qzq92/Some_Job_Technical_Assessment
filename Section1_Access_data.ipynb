{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Section 1\n","You would have received a Access_data.zip file with 22 datasets in .csv format and 1 data dictionary in .docx format. The datasets are sample of the mock-data on individuals accessing two office sites of Company ABC, consisting of:\n","\n","1. When: Time of entry by the individual\n","\n","2. Profile: Type of access card\n","    -\t0 - Staff Pass\n","    -\t1 - Temp Pass\n","    -\t2 - Visitor Pass\n","\n","3. Dept: Department of the individual\n","\n","4. CardNum: Card unique identifier. The length of the card number cannot be less than 8 characters. Currently, if CardNum starts with a/multiple ‘0’, the data captured in system will exclude/remove the “0”.\n","\n","You can assume that the total number of staff in the company is 2000 and the data is extracted from the company’s building access system. An individual can tap in and out several times within the same day. When the individual first clock in, that would be the earliest time slot and the only record you will base off the analysis. (You can also state your other assumptions if need be.)\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["## Imports\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import statsmodels as sm\n","import os"]},{"cell_type":"markdown","metadata":{},"source":["## Question 1.1\n","Write code preferably in R or Python to process and organise the raw data (Access_data.zip) to make it suitable for analysis. Identify and resolve the data quality issues in the raw data, if any. (The created code should allow user to efficiently and easily run it to ingest additional datasets of different period, beyond the given sample.)\n","\n","We assume the files are represented in the format of 'SiteAYYYYMMDD-YYYYMMDDa.csv' or 'SiteBYYYYMMDD-YYYYMMDDb.csv' for both sites respectively."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Utility function for listing particular required site files in a specified data directory path\n","def list_files_for_a_site(site_name):\n","    data_dir_path=os.path.join(os.getcwd(), \"data\", \"Access_Data\")\n","    return [os.path.join(data_dir_path, file) for file in os.listdir(data_dir_path) if file.startswith(site_name)]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200420-20200426a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200427-20200503a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200504-20200510a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200511-20200517a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200518-20200524a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200525-20200531a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200601a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200602-20200608a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200609-20200614a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200615-20200621a.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteA20200622-20200628a.csv']\n","['c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200420-20200426b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200427-20200503b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200504-20200510b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200511-20200517b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200518-20200524b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200525-20200531b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200601b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200602-20200607b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200608-20200614b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200615-20200621b.csv', 'c:\\\\Users\\\\quekz\\\\OneDrive\\\\Desktop\\\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\\\data\\\\Access_Data\\\\SiteB20200622-20200628b.csv']\n"]}],"source":["# Construct list of site A and site B files.\n","site_A_file_list =  list_files_for_a_site(site_name=\"SiteA\")\n","site_B_file_list =  list_files_for_a_site(site_name=\"SiteB\")\n","\n","print(site_A_file_list)\n","print(site_B_file_list)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def column_checker(df, filename):\n","    expected_col = set([\"When\", \"Profile\", \"Dept\", \"CardNum\"])\n","    symmetric_diff_set = set(df.columns).symmetric_difference(expected_col)\n","    if symmetric_diff_set :\n","        print(f\"Identified a non-expected column for {filename}\")\n","        print(f\"Symmetric difference: {symmetric_diff_set}\")\n","    return None"]},{"cell_type":"markdown","metadata":{},"source":["### Process site A and site B\n","\n","Do a quick check on column name and found that one of site A data file has column named \"Depts\" instead of \"Dept\" while for site B, there is a column named \"CardNum \" instead of \"CardNum\" for same period of 20200622-20200628. To resolve this issue, we will strip all leading/trailing space and extract the first 4 alphanumeric representation for convenience"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Identified a non-expected column for c:\\Users\\quekz\\OneDrive\\Desktop\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\data\\Access_Data\\SiteA20200622-20200628a.csv\n","Symmetric difference: {'Depts', 'Dept'}\n","\n","Identified a non-expected column for c:\\Users\\quekz\\OneDrive\\Desktop\\MOM_Senior-Analyst-Analyst_SensingAnalytics_Assessment\\data\\Access_Data\\SiteB20200622-20200628b.csv\n","Symmetric difference: {'CardNum ', 'CardNum'}\n"]}],"source":["for file in site_A_file_list:\n","    temp_df = pd.read_csv(file, sep=\",\")\n","    column_checker(temp_df, file)\n","\n","print()\n","for file in site_B_file_list:\n","    temp_df = pd.read_csv(file, sep=\",\")\n","    column_checker(temp_df, file)"]},{"cell_type":"markdown","metadata":{},"source":["Append the loaded dataframe into a list for vertical stacking. We assume the time period for both sites will be Apr 20 2020 to Jun 28 2020 based on file name date representation.\n","\n","Notice that there are quite a significant number of nulls for Department feature in Site A (9266) and Site B (10100); and 5 null card information for site B."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 12192 entries, 0 to 12191\n","Data columns (total 6 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   When    12192 non-null  object\n"," 1   Prof    12192 non-null  object\n"," 2   Dept    2925 non-null   object\n"," 3   Card    12192 non-null  object\n"," 4   Time    12192 non-null  object\n"," 5   Date    12192 non-null  object\n","dtypes: object(6)\n","memory usage: 571.6+ KB\n","None\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 24499 entries, 0 to 24498\n","Data columns (total 6 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   When    24499 non-null  object\n"," 1   Prof    24499 non-null  object\n"," 2   Dept    14399 non-null  object\n"," 3   Card    24494 non-null  object\n"," 4   Time    24499 non-null  object\n"," 5   Date    24499 non-null  object\n","dtypes: object(6)\n","memory usage: 1.1+ MB\n","None\n"]}],"source":["site_A_df_list = []\n","for file in site_A_file_list:\n","    temp_df = pd.read_csv(file, sep=\",\")\n","    temp_df.columns = [col.strip()[:4] for col in temp_df.columns]\n","    site_A_df_list.append(temp_df)\n","\n","site_B_df_list = []\n","for file in site_B_file_list:\n","    temp_df = pd.read_csv(file, sep=\",\")\n","    temp_df.columns = [col.strip()[:4] for col in temp_df.columns]\n","    site_B_df_list.append(temp_df)\n","\n","\n","site_A_df = pd.concat(site_A_df_list, ignore_index=True)\n","site_B_df = pd.concat(site_B_df_list, ignore_index=True)\n","\n","# Split When into Date and TIme\n","site_A_df[['Time', 'Date']] = site_A_df['When'].str.split(' ', expand=True)\n","site_B_df[['Time', 'Date']] = site_B_df['When'].str.split(' ', expand=True)\n","\n","print(site_A_df.info())\n","print(site_B_df.info())"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Convert card type to string in case of int and string mix representation\n","site_A_df[\"Card\"] = site_A_df[\"Card\"].astype(str)"]},{"cell_type":"markdown","metadata":{},"source":["Check Department and Profile uniqueness for both sides as they are categorical. Notice that for Site A, we see that there is some form of discrepancy for Dept 1, as well as the Profile value represented in numeric or string format.\n","\n","To simplify department representation, we will remove all spaces and concatenate the alphanumeric representation, while for profile representation, we will do a string cast and standardise to meaningful name representation"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[nan 'Dept 5' 'Dept 11' 'Dept 18' 'Dept 4' 'Dept 9' 'Dept 15' 'Dept 14'\n"," 'Dept 2' 'Dept 8' 'Dept 12' 'Dept  1' 'Dept 1' 'Dept 19' 'Dept 7'\n"," 'Dept 17' 'Dept 10' 'Dept 6' 'Dept 3' 'Dept 16' 'Dept 13']\n","[2 1 0 '1' '0' '2' 'Visitor Pass']\n"]}],"source":["print(site_A_df[\"Dept\"].unique())\n","print(site_A_df[\"Prof\"].unique())"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["profile_pass_mapping = {\n","    \"0\": \"Staff Pass\",\n","    \"1\": \"Temp Pass\",\n","    \"2\": \"Visitor Pass\"\n","}\n","\n","site_A_df[\"Dept\"] = site_A_df[\"Dept\"].fillna(\"unknown\")\n","site_A_df[\"Dept\"] = site_A_df[\"Dept\"].map(lambda x: x.replace(\" \",\"\") if x else x)\n","\n","site_A_df[\"Prof\"] = site_A_df[\"Prof\"].map(lambda x: str(x))\n","site_A_df[\"Prof\"] = site_A_df[\"Prof\"].map(lambda x: profile_pass_mapping[x] if x in profile_pass_mapping else x)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['unknown' 'Dept5' 'Dept11' 'Dept18' 'Dept4' 'Dept9' 'Dept15' 'Dept14'\n"," 'Dept2' 'Dept8' 'Dept12' 'Dept1' 'Dept19' 'Dept7' 'Dept17' 'Dept10'\n"," 'Dept6' 'Dept3' 'Dept16' 'Dept13']\n","['Visitor Pass' 'Temp Pass' 'Staff Pass']\n"]}],"source":["print(site_A_df[\"Dept\"].unique())\n","print(site_A_df[\"Prof\"].unique())"]},{"cell_type":"markdown","metadata":{},"source":["Handle missing data for Site A involving department feature. Identify the pass type (profile) which the department information is unknown. We need to check from the perspective of each pass type(profile) and see the applicability of department before deciding how to impute.\n","\n","Checking from this 2 perspective, we conclude that the department information is not applicable for both temp/visitor pass. We can fill as not applicable representation."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["array(['Visitor Pass', 'Temp Pass'], dtype=object)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Identify the pass type (profile) which the department information is unknown, as we need to impute\n","site_A_df[site_A_df[\"Dept\"]==\"unknown\"][\"Prof\"].unique()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Visitor Pass:['unknown']\n","Temp Pass:['unknown']\n","Staff Pass:['Dept5' 'Dept11' 'Dept18' 'Dept4' 'Dept9' 'Dept15' 'Dept14' 'Dept2'\n"," 'Dept8' 'Dept12' 'Dept1' 'Dept19' 'Dept7' 'Dept17' 'Dept10' 'Dept6'\n"," 'Dept3' 'Dept16' 'Dept13']\n"]}],"source":["# For each pass type (profile), see its applicability to department information\n","for profile in site_A_df[\"Prof\"].unique():\n","    unique_dept = site_A_df[site_A_df[\"Prof\"]==profile][\"Dept\"].unique()\n","    print(f\"{profile}:{unique_dept}\")"]},{"cell_type":"markdown","metadata":{},"source":["Similarity check for site B"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# Convert card type to string in case of int and string mix representation\n","site_B_df[\"Card\"] = site_B_df[\"Card\"].astype(str)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Dept 4' nan 'Dept 2' 'Dept 16' 'Dept 10' 'Dept 5' 'Dept 14' 'Dept 3'\n"," 'Dept 15' 'Dept 8' 'Dept 13' 'Dept 19' 'Dept 11' 'Dept 9' 'Dept 18'\n"," 'Dept 7' 'Dept 17' 'Dept 1' 'Dept 12' 'Dept 6']\n","[0 1 2 '0' '1' '2' 'Temp Pass' 'Staff Pass']\n"]}],"source":["print(site_B_df[\"Dept\"].unique())\n","print(site_B_df[\"Prof\"].unique())"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["site_B_df[\"Dept\"] = site_B_df[\"Dept\"].fillna(\"unknown\")\n","site_B_df[\"Dept\"] = site_B_df[\"Dept\"].map(lambda x: x.replace(\" \",\"\") if x else x)\n","\n","site_B_df[\"Prof\"] = site_B_df[\"Prof\"].map(lambda x: str(x))\n","site_B_df[\"Prof\"] = site_B_df[\"Prof\"].map(lambda x: profile_pass_mapping[x] if x in profile_pass_mapping else x)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Dept4' 'unknown' 'Dept2' 'Dept16' 'Dept10' 'Dept5' 'Dept14' 'Dept3'\n"," 'Dept15' 'Dept8' 'Dept13' 'Dept19' 'Dept11' 'Dept9' 'Dept18' 'Dept7'\n"," 'Dept17' 'Dept1' 'Dept12' 'Dept6']\n","['Staff Pass' 'Temp Pass' 'Visitor Pass']\n"]}],"source":["print(site_B_df[\"Dept\"].unique())\n","print(site_B_df[\"Prof\"].unique())"]},{"cell_type":"markdown","metadata":{},"source":["Handle missing data for Site B involving Department feature.\n","\n","For Department, identify the profile which department info is unknown. We also need to check from the perspective of each pass type(profile) and see the uniqueness of department to decide how to impute.\n","\n","Checking from this 2 perspective, we conclude that the department information is not applicable for both temp/visitor pass. We can fill as not applicable representation."]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["array(['Temp Pass', 'Visitor Pass'], dtype=object)"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["site_B_df[site_B_df[\"Dept\"]==\"unknown\"][\"Prof\"].unique()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Staff Pass:['Dept4' 'Dept2' 'Dept16' 'Dept10' 'Dept5' 'Dept14' 'Dept3' 'Dept15'\n"," 'Dept8' 'Dept13' 'Dept19' 'Dept11' 'Dept9' 'Dept18' 'Dept7' 'Dept17'\n"," 'Dept1' 'Dept12' 'Dept6']\n","Temp Pass:['unknown']\n","Visitor Pass:['unknown']\n"]}],"source":["for profile in site_B_df[\"Prof\"].unique():\n","    unique_dept = site_B_df[site_B_df[\"Prof\"]==profile][\"Dept\"].unique()\n","    print(f\"{profile}:{unique_dept}\")"]},{"cell_type":"markdown","metadata":{},"source":["In both sites, we are sure that temp and visitor pass do not have corresponding department info. As such we will replace it with a vale as not_applicable."]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["site_A_df[\"Dept\"] = site_A_df[\"Dept\"].map(lambda x:x.replace(\"unknown\",\"not_applicable\" if x==\"unknown\" else x))\n","site_B_df[\"Dept\"] = site_B_df[\"Dept\"].map(lambda x:x.replace(\"unknown\",\"not_applicable\" if x==\"unknown\" else x))"]},{"cell_type":"markdown","metadata":{},"source":["We still have null cases where card information is unknown. A quick check shows the card affected are either temp pass/visitor pass. We may want to combine the dataframe from 2 sites to resolve the card information issue as no additional information are provided."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>When</th>\n","      <th>Prof</th>\n","      <th>Dept</th>\n","      <th>Card</th>\n","      <th>Time</th>\n","      <th>Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2429</th>\n","      <td>26/4/2020 7:31</td>\n","      <td>Temp Pass</td>\n","      <td>unknown</td>\n","      <td>NaN</td>\n","      <td>26/4/2020</td>\n","      <td>7:31</td>\n","    </tr>\n","    <tr>\n","      <th>2430</th>\n","      <td>24/4/2020 7:34</td>\n","      <td>Temp Pass</td>\n","      <td>unknown</td>\n","      <td>NaN</td>\n","      <td>24/4/2020</td>\n","      <td>7:34</td>\n","    </tr>\n","    <tr>\n","      <th>2431</th>\n","      <td>22/4/2020 7:27</td>\n","      <td>Temp Pass</td>\n","      <td>unknown</td>\n","      <td>NaN</td>\n","      <td>22/4/2020</td>\n","      <td>7:27</td>\n","    </tr>\n","    <tr>\n","      <th>4715</th>\n","      <td>3/5/2020 8:32</td>\n","      <td>Visitor Pass</td>\n","      <td>unknown</td>\n","      <td>NaN</td>\n","      <td>3/5/2020</td>\n","      <td>8:32</td>\n","    </tr>\n","    <tr>\n","      <th>6985</th>\n","      <td>8/5/2020 9:42</td>\n","      <td>Visitor Pass</td>\n","      <td>unknown</td>\n","      <td>NaN</td>\n","      <td>8/5/2020</td>\n","      <td>9:42</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                When          Prof     Dept Card       Time  Date\n","2429  26/4/2020 7:31     Temp Pass  unknown  NaN  26/4/2020  7:31\n","2430  24/4/2020 7:34     Temp Pass  unknown  NaN  24/4/2020  7:34\n","2431  22/4/2020 7:27     Temp Pass  unknown  NaN  22/4/2020  7:27\n","4715   3/5/2020 8:32  Visitor Pass  unknown  NaN   3/5/2020  8:32\n","6985   8/5/2020 9:42  Visitor Pass  unknown  NaN   8/5/2020  9:42"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["site_B_df[site_B_df[\"Card\"].isna()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a new identifier row for both dataframe\n","site_A_df[\"Site\"] = \"A\"\n","site_B_df[\"Site\"] = \"B\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"mom_assesment","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
